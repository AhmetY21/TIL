<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Semantic Analogies with Word Vectors</title>
  <script>
    if (localStorage.theme === 'dark' || (!('theme' in localStorage) && window.matchMedia('(prefers-color-scheme: dark)').matches)) {
      document.documentElement.classList.add('dark');
    } else {
      document.documentElement.classList.remove('dark');
    }
  </script>
  <style>
    body {
      font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
      line-height: 1.6;
      max-width: 900px;
      margin: 0 auto;
      padding: 24px;
      color: #111827;
      background: #ffffff;
    }
    h1, h2, h3 { color: #111827; }
    a { color: #2563eb; text-decoration: none; }
    a:hover { text-decoration: underline; }
    code { background-color: #f3f4f6; padding: 2px 6px; border-radius: 6px; }
    pre { background-color: #0b1020; color: #e5e7eb; padding: 16px; border-radius: 10px; overflow-x: auto; }
    pre code { background: transparent; padding: 0; }
    blockquote { border-left: 4px solid #e5e7eb; margin: 0; padding-left: 16px; color: #4b5563; }
    table { width: 100%; border-collapse: collapse; margin: 16px 0; }
    th, td { border: 1px solid #e5e7eb; padding: 8px; text-align: left; }
    th { background: #f9fafb; }
    hr { border: none; border-top: 1px solid #e5e7eb; margin: 24px 0; }

    .page-header {
      display: flex;
      justify-content: space-between;
      align-items: center;
      margin-bottom: 24px;
      padding-bottom: 16px;
      border-bottom: 1px solid #e5e7eb;
    }
    .back-link {
      font-weight: 600;
      text-decoration: none;
    }
    .back-link:hover {
      text-decoration: underline;
    }

    .theme-toggle {
      background: none;
      border: none;
      cursor: pointer;
      font-size: 1.5rem;
      padding: 8px;
      border-radius: 50%;
      transition: background 0.2s;
    }
    .theme-toggle:hover {
      background: rgba(0,0,0,0.05);
    }
    .dark .theme-toggle:hover {
      background: rgba(255,255,255,0.1);
    }

    .dark body {
      background: #0f172a;
      color: #e2e8f0;
    }
    .dark h1, .dark h2, .dark h3 { color: #f1f5f9; }
    .dark a { color: #60a5fa; }
    .dark .page-header { border-bottom-color: #334155; }
    .dark code { background-color: #1e293b; color: #e2e8f0; }
    .dark pre {
      border: 1px solid #334155;
    }
    .dark blockquote {
      border-left-color: #334155;
      color: #94a3b8;
    }
    .dark th, .dark td { border-color: #334155; }
    .dark th { background: #1e293b; }
    .dark hr { border-top-color: #334155; }

    /* Copy Button */
    pre { position: relative; }
    .copy-button {
      position: absolute;
      top: 8px;
      right: 8px;
      padding: 4px 8px;
      font-size: 0.8rem;
      color: #94a3b8;
      background: rgba(255, 255, 255, 0.1);
      border: 1px solid rgba(255, 255, 255, 0.1);
      border-radius: 4px;
      cursor: pointer;
      opacity: 0;
      transition: opacity 0.2s, background 0.2s;
    }
    pre:hover .copy-button, .copy-button:focus {
      opacity: 1;
    }
    .copy-button:hover {
      background: rgba(255, 255, 255, 0.2);
      color: #e2e8f0;
    }
  </style>
</head>
<body>

  <div class="page-header">
    <a href="../../../../../hubs/nlp-index.html" class="back-link">‚Üê Back to Natural Language Processing</a>
    <button id="theme-toggle" class="theme-toggle" aria-label="Toggle Dark Mode">üåô</button>
  </div>

<h1 id="topic-semantic-analogies-with-word-vectors">Topic: Semantic Analogies with Word Vectors</h1>
<h2 id="1-formal-definition-what-is-it-and-how-can-we-use-it">1) Formal definition (what is it, and how can we use it?)</h2>
<p>Semantic analogies with word vectors leverage the ability of word embeddings (like Word2Vec, GloVe, or fastText) to capture semantic relationships between words. The core idea is to express an analogy of the form "A is to B as C is to D" using vector arithmetic.</p>
<p>Formally, given words A, B, and C, we want to find a word D that satisfies the analogy "A:B :: C:D".  This is achieved by searching for a word vector <em>v_D</em> that is close to the vector <em>v_B - v_A + v_C</em>.</p>
<p>In other words, we assume that the relationship between A and B can be represented as a vector difference <em>v_B - v_A</em>. We then apply this same relationship to word C to find the analogous word D. We find D by adding this relationship to C's vector representation:  <em>v_D ‚âà v_C + (v_B - v_A)</em>. The word whose vector is closest to the calculated <em>v_D</em> in the embedding space is then predicted as the solution.</p>
<p>More formally:</p>
<ul>
<li>We are given word vectors  v_A, v_B, and v_C.</li>
<li>We want to find v_D such that: <code>v_D ‚âà v_C + (v_B - v_A)</code></li>
<li>We find the word D whose vector embedding is closest (using cosine similarity or other distance metrics) to the calculated vector <code>v_C + (v_B - v_A)</code>.</li>
</ul>
<p><strong>How can we use it?</strong></p>
<ul>
<li><strong>Reasoning:</strong> Test the ability of a word embedding model to capture relational knowledge (e.g., "king - man + woman = queen").</li>
<li><strong>Knowledge Discovery:</strong> Discover novel relationships between entities based on existing knowledge encoded in the word embeddings.</li>
<li><strong>Completing Analogies:</strong> Given "A is to B as C is to ?", predict the most suitable word to fill the blank.</li>
<li><strong>Word Sense Disambiguation:</strong> Choose the appropriate sense of a word based on its context within an analogy.</li>
</ul>
<h2 id="2-application-scenario">2) Application scenario</h2>
<p><strong>Scenario:</strong>  Language learning and teaching.</p>
<p>Imagine you are building a language learning application that helps users understand grammatical relationships. You want to demonstrate the concept of adjective comparisons (e.g., "tall", "taller", "tallest").</p>
<p>Using semantic analogies, you could present the following analogy:</p>
<p>"Good is to better as bad is to what?"</p>
<p>The application would use word vectors to calculate: <code>v_better - v_good + v_bad</code> and then find the word vector closest to the result. If the word embedding is well-trained, it should return "worse" as the answer, visually demonstrating the parallel grammatical structure. This makes the abstract concept of adjective comparison more tangible for the learner.</p>
<p>Another example is with country and capital cities: "Germany is to Berlin as France is to?"</p>
<h2 id="3-python-method-if-possible">3) Python method (if possible)</h2>
<pre class="codehilite"><code class="language-python">import numpy as np
from sklearn.metrics.pairwise import cosine_similarity

def analogy(word1, word2, word3, word_vectors):
    &quot;&quot;&quot;
    Solves the analogy &quot;word1 is to word2 as word3 is to ?&quot;

    Args:
        word1: The first word (string).
        word2: The second word (string).
        word3: The third word (string).
        word_vectors: A dictionary where keys are words (strings) and values are their corresponding vector representations (numpy arrays).

    Returns:
        The word (string) that best completes the analogy.
    &quot;&quot;&quot;

    word1_vec = word_vectors[word1]
    word2_vec = word_vectors[word2]
    word3_vec = word_vectors[word3]

    # Calculate the target vector
    target_vec = word2_vec - word1_vec + word3_vec

    # Find the word with the closest vector
    best_word = None
    best_similarity = -1  # Initialize with a low value

    for word, vec in word_vectors.items():
        if word not in [word1, word2, word3]:  # Exclude the input words
            similarity = cosine_similarity([target_vec], [vec])[0][0] # cosine_similarity returns a matrix, so we get the scalar out

            if similarity &gt; best_similarity:
                best_similarity = similarity
                best_word = word

    return best_word


# Example usage (assuming you have a dictionary of word vectors)
# In a real application, you'd load pre-trained word vectors.
# Here's a toy example:
word_vectors = {
    &quot;king&quot;: np.array([0.9, 0.1, 0.3, 0.5]),
    &quot;man&quot;: np.array([0.8, 0.2, 0.4, 0.6]),
    &quot;woman&quot;: np.array([0.7, 0.3, 0.5, 0.7]),
    &quot;queen&quot;: np.array([0.6, 0.4, 0.6, 0.8]),
    &quot;germany&quot;: np.array([0.1, 0.9, 0.2, 0.8]),
    &quot;berlin&quot;: np.array([0.2, 0.8, 0.3, 0.7]),
    &quot;france&quot;: np.array([0.3, 0.7, 0.4, 0.6]),
    &quot;paris&quot;: np.array([0.4, 0.6, 0.5, 0.5])

}

result = analogy(&quot;man&quot;, &quot;king&quot;, &quot;woman&quot;, word_vectors)
print(f&quot;man:king :: woman:{result}&quot;) # Expected: queen

result = analogy(&quot;germany&quot;, &quot;berlin&quot;, &quot;france&quot;, word_vectors)
print(f&quot;germany:berlin :: france:{result}&quot;) # Expected: paris
</code></pre>

<h2 id="4-follow-up-question">4) Follow-up question</h2>
<p>How does the choice of word embedding model (Word2Vec, GloVe, fastText) influence the accuracy of solving semantic analogies, and why? What are some limitations of using this approach to solve analogies?</p>
  <script>
    const btn = document.getElementById('theme-toggle');
    const html = document.documentElement;
    
    function updateIcon() {
      btn.textContent = html.classList.contains('dark') ? '‚òÄÔ∏è' : 'üåô';
    }
    
    // Set initial icon
    updateIcon();

    btn.addEventListener('click', () => {
      if (html.classList.contains('dark')) {
        html.classList.remove('dark');
        localStorage.theme = 'light';
      } else {
        html.classList.add('dark');
        localStorage.theme = 'dark';
      }
      updateIcon();
    });

    // Copy Code Functionality
    document.querySelectorAll('pre').forEach(pre => {
      const button = document.createElement('button');
      button.className = 'copy-button';
      button.textContent = 'Copy';
      button.setAttribute('aria-label', 'Copy code to clipboard');

      pre.appendChild(button);

      button.addEventListener('click', async () => {
        const code = pre.querySelector('code');
        if (!code) return;

        try {
          await navigator.clipboard.writeText(code.innerText);
          button.textContent = 'Copied!';
          setTimeout(() => {
            button.textContent = 'Copy';
          }, 2000);
        } catch (err) {
          console.error('Failed to copy:', err);
          button.textContent = 'Error';
        }
      });
    });
  </script>
</body>
</html>
