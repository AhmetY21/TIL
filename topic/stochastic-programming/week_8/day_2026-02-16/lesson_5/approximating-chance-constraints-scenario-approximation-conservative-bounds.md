---
title: "Approximating Chance Constraints (scenario approximation / conservative bounds)"
date: "2026-02-16"
week: 8
lesson: 5
slug: "approximating-chance-constraints-scenario-approximation-conservative-bounds"
---

# Topic: Approximating Chance Constraints (scenario approximation / conservative bounds)

## 1) Formal definition (what is it, and how can we use it?)

Chance constraints, also known as probabilistic constraints, are constraints that must hold with a specified probability.  They express the requirement that a constraint, which depends on random parameters, holds with at least a certain confidence level.  Mathematically, a chance constraint has the general form:

```
P(g(x, ξ) <= 0) >= 1 - α
```

where:

*   `x` is the decision variable vector.
*   `ξ` is a random vector representing uncertain parameters.
*   `g(x, ξ)` is a function describing the constraint, which depends on both the decision variable and the random parameters.
*   `α` is the acceptable violation probability (typically a small value like 0.05 or 0.1), and `1 - α` is the desired confidence level.
*   `P(.)` denotes the probability measure.

Directly solving optimization problems with chance constraints is often computationally intractable because evaluating the probability `P(g(x, ξ) <= 0)` can be difficult or impossible. This is especially true when the distribution of `ξ` is complex or unknown.

Approximating chance constraints involves replacing the probabilistic constraint with a deterministic approximation that is easier to solve. *Scenario approximation* and *conservative bounds* are two common techniques for this.

**Scenario Approximation (Sample Average Approximation - SAA):**

Scenario approximation replaces the probability with an empirical estimate obtained by sampling the random variable `ξ`.  We generate `N` independent samples (scenarios) `ξ_1, ξ_2, ..., ξ_N` from the distribution of `ξ`.  The chance constraint is then approximated by requiring the constraint `g(x, ξ_i) <= 0` to hold for a sufficient number of scenarios. The most common approach is to require the constraint to hold for *all* scenarios, resulting in a deterministic problem:

```
g(x, ξ_i) <= 0  for all i = 1, ..., N
```

The problem then becomes:

```
minimize f(x)
subject to:
g(x, ξ_i) <= 0  for all i = 1, ..., N
x ∈ X
```

where `f(x)` is the objective function and `X` represents other deterministic constraints on `x`.

SAA provides a statistical guarantee on the quality of the solution as `N` increases.  Specifically, under certain assumptions, as `N` goes to infinity, the solution to the SAA problem converges to the solution of the original chance-constrained problem. The number of samples `N` required depends on the problem's complexity and the desired confidence level.

**Conservative Bounds:**

Conservative bounds replace the chance constraint with a more restrictive deterministic constraint that is guaranteed to be feasible if the original chance constraint is feasible. These bounds are typically derived by exploiting properties of the distribution of `ξ` or by using inequalities to relate the probability to other quantities.  Examples include using Chebyshev's inequality or transforming the chance constraint into an equivalent robust optimization problem.  The "conservativeness" comes from the fact that satisfying the deterministic constraint is a *sufficient* condition for satisfying the chance constraint, but not necessarily a *necessary* one. Thus, the resulting solution may be suboptimal compared to the ideal solution of the true chance-constrained problem.

**How to use it:**

1.  **Identify the random parameters (ξ) and their distributions (or samples).**
2.  **Formulate the constraint function g(x, ξ).**
3.  **Choose a method (SAA or conservative bound).**
4.  **For SAA, generate a sufficient number of samples (scenarios).**
5.  **Formulate the deterministic approximation of the chance constraint.**
6.  **Solve the resulting deterministic optimization problem.**
7.  **(For SAA) Assess the quality of the solution (e.g., through out-of-sample validation or statistical tests). Increase the number of samples if necessary.**

## 2) Application scenario

Consider a power grid operator who needs to schedule electricity generation to meet demand while ensuring the grid's reliability.  The demand is uncertain and can be modeled as a random variable. The grid operator wants to ensure that the total generation capacity is sufficient to meet the demand with a high probability (e.g., 95%).

Let:

*   `x_i` be the amount of electricity generated by generator `i`.
*   `ξ` be the random variable representing the total electricity demand.
*   `C_i` be the generation capacity of generator `i`.
*   `α` be the acceptable probability of demand exceeding generation.

The chance constraint is:

```
P(∑_{i=1}^{n} x_i >= ξ) >= 1 - α
```

where `n` is the number of generators. Also:

```
0 <= x_i <= C_i
```

**Applying Scenario Approximation:**

The grid operator can generate `N` scenarios of electricity demand, `ξ_1, ξ_2, ..., ξ_N`, based on historical data and weather forecasts.  The chance constraint is then approximated by:

```
∑_{i=1}^{n} x_i >= ξ_j  for all j = 1, ..., N
```

The operator then minimizes the cost of generation (objective function) subject to these constraints and the capacity constraints.

**Applying a Conservative Bound:**

If the distribution of demand (`ξ`) is known, the operator could use Chebyshev's inequality. Let `μ` be the mean demand and `σ` be the standard deviation. Chebyshev's inequality states:

```
P(|ξ - μ| >= kσ) <= 1/k^2
```

We want `P(ξ > ∑_{i=1}^{n} x_i) <= α`.  Rearranging, `P(∑_{i=1}^{n} x_i >= ξ) >= 1-α`.  A conservative approach could involve choosing `∑_{i=1}^{n} x_i`  such that it's at least `kσ` above the mean demand `μ`, where `1/k^2 = α`.  Therefore, `k = 1/sqrt(α)`. The deterministic constraint becomes:

```
∑_{i=1}^{n} x_i >= μ + (1/sqrt(α)) * σ
```

This constraint is more restrictive than the original chance constraint, but it is deterministic and easier to solve. The operator would then minimize the cost of generation subject to this conservative deterministic constraint and the capacity constraints.  Note that the choice of `k` directly influences the conservativeness of the bound.

## 3) Python method (if possible)

Using Pyomo and NumPy, we can demonstrate SAA. This example shows how to formulate and solve a simple SAA problem in Python. It's a basic illustration and needs adaptation for specific problems.

```python
import pyomo.environ as pyo
import numpy as np

# Example: Minimize x subject to P(a*x >= b) >= 0.95, where a and b are random
# and x >= 0

# 1. Generate scenarios
num_scenarios = 100
np.random.seed(42) # for reproducibility
a_scenarios = np.random.normal(loc=1.0, scale=0.2, size=num_scenarios) # normally distributed 'a'
b_scenarios = np.random.normal(loc=0.5, scale=0.1, size=num_scenarios) # normally distributed 'b'


# 2. Create Pyomo model
model = pyo.ConcreteModel()

# 3. Define decision variable
model.x = pyo.Var(domain=pyo.NonNegativeReals)

# 4. Define objective function
model.objective = pyo.Objective(expr=model.x, sense=pyo.minimize)

# 5. Define scenarios as a set (needed for indexed constraints)
model.scenarios = pyo.Set(initialize=range(num_scenarios))


# 6. Define chance constraint (approximated by scenario constraints)
def scenario_constraint_rule(model, s):
  return a_scenarios[s] * model.x >= b_scenarios[s]

model.scenario_constraints = pyo.Constraint(model.scenarios, rule=scenario_constraint_rule)


# 7. Solve the model
solver = pyo.SolverFactory('ipopt')  # Choose an appropriate solver
results = solver.solve(model)

# 8. Print the solution
if results.solver.status == pyo.SolverStatus.ok and results.solver.termination_condition == pyo.TerminationCondition.optimal:
    print("Optimal solution found:")
    print("x =", pyo.value(model.x))
else:
    print("Solver did not find an optimal solution.")
    print(results.solver)

# Optional: Evaluate solution on out-of-sample data to estimate constraint violation
# (This step is crucial in practice to assess solution quality)
num_out_of_sample = 1000
a_out_of_sample = np.random.normal(loc=1.0, scale=0.2, size=num_out_of_sample)
b_out_of_sample = np.random.normal(loc=0.5, scale=0.1, size=num_out_of_sample)

violation_count = 0
for i in range(num_out_of_sample):
  if a_out_of_sample[i] * pyo.value(model.x) < b_out_of_sample[i]:
    violation_count += 1

violation_probability_estimate = violation_count / num_out_of_sample
print(f"Estimated violation probability (out-of-sample): {violation_probability_estimate}")
```

**Explanation:**

1.  **Generate Scenarios:**  We use `numpy` to generate `num_scenarios` realizations of the random parameters `a` and `b` from normal distributions.
2.  **Create Pyomo Model:** We create a `ConcreteModel` in Pyomo.
3.  **Define Decision Variable:** `model.x` is the decision variable we want to optimize.
4.  **Define Objective Function:** We want to minimize `x`.
5.  **Define Scenarios Set:** We define a set `model.scenarios` to iterate through our scenarios. This is crucial for creating indexed constraints.
6.  **Define Scenario Constraints:** The `scenario_constraint_rule` function defines the constraint for each scenario. This is the core of the SAA approach. Pyomo's `Constraint` object is then used to create constraints for *each* scenario.
7.  **Solve the Model:**  We use the `ipopt` solver (installable via `conda install -c conda-forge ipopt` or similar). Choose an appropriate solver based on your problem's characteristics.
8.  **Print the Solution:**  If the solver finds an optimal solution, we print the optimal value of `x`.
9.  **Out-of-Sample Validation:**  After solving, it's crucial to *validate* the solution using out-of-sample data. We generate new samples and check how often the constraint is violated with the obtained `x` value. This provides an *estimate* of the actual violation probability. This is a key step for assessing the reliability of the SAA solution. If the estimated violation probability is greater than `alpha` (0.05 in this case), then the number of scenarios should be increased.

**Important Notes:**

*   Choose a suitable solver based on the problem type (linear, nonlinear, etc.).
*   The number of scenarios `num_scenarios` significantly impacts the solution quality. Use out-of-sample validation to determine if more scenarios are needed.
*   This is a basic example.  Real-world problems are more complex and may require more sophisticated modeling techniques.

## 4) Follow-up question

How can we determine the minimum number of scenarios required for the Sample Average Approximation (SAA) method to achieve a certain level of accuracy and confidence in the solution of a chance-constrained optimization problem? Are there theoretical results or practical guidelines for selecting the appropriate sample size?