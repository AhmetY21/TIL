<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>DoWhy Workflow: Model ‚Üí Identify ‚Üí Estimate ‚Üí Refute</title>
  <script>
    if (localStorage.theme === 'dark' || (!('theme' in localStorage) && window.matchMedia('(prefers-color-scheme: dark)').matches)) {
      document.documentElement.classList.add('dark');
    } else {
      document.documentElement.classList.remove('dark');
    }
  </script>
  <style>
    body {
      font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
      line-height: 1.6;
      max-width: 900px;
      margin: 0 auto;
      padding: 24px;
      color: #111827;
      background: #ffffff;
    }
    h1, h2, h3 { color: #111827; }
    a { color: #2563eb; text-decoration: none; }
    a:hover { text-decoration: underline; }
    code { background-color: #f3f4f6; padding: 2px 6px; border-radius: 6px; }
    pre { background-color: #0b1020; color: #e5e7eb; padding: 16px; border-radius: 10px; overflow-x: auto; }
    pre code { background: transparent; padding: 0; }
    blockquote { border-left: 4px solid #e5e7eb; margin: 0; padding-left: 16px; color: #4b5563; }
    table { width: 100%; border-collapse: collapse; margin: 16px 0; }
    th, td { border: 1px solid #e5e7eb; padding: 8px; text-align: left; }
    th { background: #f9fafb; }
    hr { border: none; border-top: 1px solid #e5e7eb; margin: 24px 0; }

    .page-header {
      display: flex;
      justify-content: space-between;
      align-items: center;
      margin-bottom: 24px;
      padding-bottom: 16px;
      border-bottom: 1px solid #e5e7eb;
    }
    .back-link {
      font-weight: 600;
      text-decoration: none;
    }
    .back-link:hover {
      text-decoration: underline;
    }

    .theme-toggle {
      background: none;
      border: none;
      cursor: pointer;
      font-size: 1.5rem;
      padding: 8px;
      border-radius: 50%;
      transition: background 0.2s;
    }
    .theme-toggle:hover {
      background: rgba(0,0,0,0.05);
    }
    .dark .theme-toggle:hover {
      background: rgba(255,255,255,0.1);
    }

    .dark body {
      background: #0f172a;
      color: #e2e8f0;
    }
    .dark h1, .dark h2, .dark h3 { color: #f1f5f9; }
    .dark a { color: #60a5fa; }
    .dark .page-header { border-bottom-color: #334155; }
    .dark code { background-color: #1e293b; color: #e2e8f0; }
    .dark pre {
      border: 1px solid #334155;
    }
    .dark blockquote {
      border-left-color: #334155;
      color: #94a3b8;
    }
    .dark th, .dark td { border-color: #334155; }
    .dark th { background: #1e293b; }
    .dark hr { border-top-color: #334155; }

    /* Skip to Content Link */
    .skip-link {
      position: absolute;
      top: -40px;
      left: 0;
      background: #2563eb;
      color: white;
      padding: 8px;
      z-index: 100;
      transition: top 0.2s;
      font-weight: bold;
      text-decoration: none;
      border-radius: 0 0 4px 0;
    }
    .skip-link:focus {
      top: 0;
    }
    .dark .skip-link {
      background: #60a5fa;
      color: #0f172a;
    }

  </style>
</head>
<body>
  <a href="#main-content" class="skip-link">Skip to content</a>

  <div class="page-header">
    <a href="../../../../../hubs/causal-inference-index.html" class="back-link">‚Üê Back to Causal Inference</a>
    <button id="theme-toggle" class="theme-toggle" aria-label="Toggle Dark Mode">üåô</button>
  </div>

<div id="main-content" tabindex="-1"></div>
<h1 id="topic-dowhy-workflow-model-identify-estimate-refute">Topic: DoWhy Workflow: Model ‚Üí Identify ‚Üí Estimate ‚Üí Refute</h1>
<h2 id="1-formal-definition-what-is-it-and-how-can-we-use-it">1) Formal definition (what is it, and how can we use it?)</h2>
<p>The DoWhy workflow, comprising the steps <strong>Model ‚Üí Identify ‚Üí Estimate ‚Üí Refute</strong>, is a structured approach to causal inference using the DoWhy Python library. It aims to provide a principled and robust way to estimate causal effects from observational data. Let's break down each step:</p>
<ul>
<li>
<p><strong>Model (Causal Graph):</strong> This step involves explicitly representing your causal assumptions in the form of a causal graph (Directed Acyclic Graph, or DAG).  The DAG visualizes the relationships between variables, including which variables are assumed to cause other variables.  This step forces you to articulate your beliefs about how the world works, even before looking at the data. A correct causal graph is crucial for valid causal inference. If the graph is incorrect, downstream steps can produce biased or misleading results.  You use domain expertise and prior knowledge to build this graph.</p>
</li>
<li>
<p><strong>Identify:</strong> This step uses the causal graph from the Model step to algorithmically determine if the causal effect you are interested in is <em>identifiable</em>. Identifiability means that it is theoretically possible to estimate the causal effect from the available data, given the assumptions encoded in your graph. DoWhy leverages graph-based causal inference methods (e.g., back-door criterion, front-door criterion) to find valid adjustment sets or instrumental variables. The output of this step is an <em>identification query</em> which outlines what statistical estimand(s) (e.g., P(Y|do(X))) can be estimated from the observational data. If the effect is not identifiable based on your graph, you need to revise your graph or consider collecting different data.</p>
</li>
<li>
<p><strong>Estimate:</strong> This step takes the identification query from the Identify step and uses statistical methods to estimate the causal effect. DoWhy provides various estimation methods, including regression, matching, inverse probability weighting (IPW), and instrumental variables (IV) regression. The choice of estimator depends on the identification strategy and the nature of the data. This step yields a concrete estimate of the causal effect, along with uncertainty estimates (e.g., confidence intervals).</p>
</li>
<li>
<p><strong>Refute:</strong>  This step critically examines the robustness of the estimated causal effect by performing sensitivity analyses.  The goal is to assess how sensitive the estimated effect is to violations of the assumptions made in the earlier steps. Refutation methods test the validity of the assumptions underlying the identification strategy. For example, one refutation technique might add unobserved confounders to the model and see how much they would need to influence the relationship between treatment and outcome to invalidate the findings. Other refutation methods test the sensitivity of the estimate to variations in the treatment assignment mechanism. If the estimated effect is sensitive to plausible violations of the assumptions, the user should be more cautious in interpreting the results.</p>
</li>
</ul>
<p>By following this workflow, you increase the confidence in your causal inferences and make your reasoning more transparent and reproducible.</p>
<h2 id="2-application-scenario">2) Application scenario</h2>
<p>Imagine you want to understand the causal effect of a new job training program (treatment, <code>X</code>) on participants' income (outcome, <code>Y</code>). You have observational data on individuals who participated in the program and those who didn't. However, participants who enrolled in the program may differ systematically from non-participants (e.g., motivated people may be more likely to self-select into the program). This is a confounding variable (<code>C</code>, motivation). Also, years of experience might impact both the training program acceptance, and the subsequent income (<code>Z</code>, experience).</p>
<ol>
<li><strong>Model:</strong> You create a causal graph showing that:<ul>
<li><code>X</code> (Training) causes <code>Y</code> (Income)</li>
<li><code>C</code> (Motivation) causes both <code>X</code> (Training) and <code>Y</code> (Income)</li>
<li><code>Z</code> (Experience) causes both <code>X</code> (Training) and <code>Y</code> (Income)</li>
</ul>
</li>
<li><strong>Identify:</strong>  DoWhy uses your causal graph to identify that you can estimate the causal effect of training on income by adjusting for <code>C</code> and <code>Z</code> (backdoor criterion).</li>
<li><strong>Estimate:</strong> You use a regression model to estimate the causal effect of training on income, controlling for <code>C</code> and <code>Z</code>.</li>
<li><strong>Refute:</strong>  You perform a sensitivity analysis to check whether the estimated effect is robust to unobserved confounders that might be correlated with both training and income. For example, you might add a hypothetical unobserved confounder representing "access to resources" and examine how much the observed effect changes.</li>
</ol>
<h2 id="3-python-method-if-possible">3) Python method (if possible)</h2>
<pre class="codehilite"><code class="language-python">import dowhy
from dowhy import CausalModel
import pandas as pd

# 1. Model: Define the causal graph
# Assuming df is a Pandas DataFrame with columns 'training', 'income', 'motivation', 'experience'
graph = &quot;&quot;&quot;
digraph {
training[label=&quot;Training&quot;];
income[label=&quot;Income&quot;];
motivation[label=&quot;Motivation&quot;];
experience[label=&quot;Experience&quot;];
motivation -&gt; training;
motivation -&gt; income;
experience -&gt; training;
experience -&gt; income;
training -&gt; income;
}
&quot;&quot;&quot;

# Sample dataframe
data = {'training': [0, 1, 0, 1, 0],
        'income': [20000, 40000, 25000, 50000, 30000],
        'motivation': [3, 7, 4, 8, 5],
        'experience': [2, 6, 3, 7, 4]}
df = pd.DataFrame(data)


# Create a causal model
model = CausalModel(
    data=df,
    graph=graph.replace(&quot;\n&quot;, &quot; &quot;),  # DoWhy needs graph in a single line
    treatment=&quot;training&quot;,
    outcome=&quot;income&quot;
)

# 2. Identify: Identify the causal effect
identified_estimand = model.identify_effect()
print(identified_estimand)

# 3. Estimate: Estimate the causal effect using a suitable method (e.g., regression)
estimate = model.estimate_effect(
    identified_estimand,
    method_name=&quot;backdoor.linear_regression&quot;,
    control_value=0,
    treatment_value=1,
)
print(estimate)

# Get the estimated effect, confidence intervals, and more
print(&quot;Causal Estimate is &quot; + str(estimate.value))

# 4. Refute: Refute the obtained estimate using various methods
refute_results = model.refute_estimate(
    identified_estimand,
    estimate,
    method_name=&quot;random_common_cause&quot;  # Test for unobserved confounders
)
print(refute_results)


refute_results_placebo = model.refute_estimate(
    identified_estimand,
    estimate,
    method_name=&quot;placebo_treatment_refuter&quot;, # Add random treatment
    placebo_type=&quot;binary&quot;
)

print(refute_results_placebo)
</code></pre>

<h2 id="4-follow-up-question">4) Follow-up question</h2>
<p>How do I choose the most appropriate refutation method for a given causal inference problem? What factors should I consider?</p>
  <script>
    const btn = document.getElementById('theme-toggle');
    const html = document.documentElement;
    
    function updateIcon() {
      btn.textContent = html.classList.contains('dark') ? '‚òÄÔ∏è' : 'üåô';
    }
    
    // Set initial icon
    updateIcon();

    btn.addEventListener('click', () => {
      if (html.classList.contains('dark')) {
        html.classList.remove('dark');
        localStorage.theme = 'light';
      } else {
        html.classList.add('dark');
        localStorage.theme = 'dark';
      }
      updateIcon();
    });
  </script>
</body>
</html>
